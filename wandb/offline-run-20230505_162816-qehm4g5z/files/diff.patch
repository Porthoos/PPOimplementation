diff --git a/.idea/other.xml b/.idea/other.xml
new file mode 100644
index 0000000..58daadc
--- /dev/null
+++ b/.idea/other.xml
@@ -0,0 +1,6 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<project version="4">
+  <component name="PySciProjectComponent">
+    <option name="PY_MATPLOTLIB_IN_TOOLWINDOW" value="false" />
+  </component>
+</project>
\ No newline at end of file
diff --git a/draw.py b/draw.py
deleted file mode 100644
index 039d98a..0000000
--- a/draw.py
+++ /dev/null
@@ -1,40 +0,0 @@
-import numpy as np
-from tensorboard.backend.event_processing import event_accumulator
-import pandas as pd
-import matplotlib.pyplot as plt
-
-
-def parse_tensorboard(path, scalars):
-    """returns a dictionary of pandas dataframes for each requested scalar"""
-    ea = event_accumulator.EventAccumulator(
-        path,
-        size_guidance={event_accumulator.SCALARS: 0},
-    )
-    _absorb_print = ea.Reload()
-    # make sure the scalars are in the event accumulator tags
-    assert all(
-        s in ea.Tags()["scalars"] for s in scalars
-    ), "some scalars were not found in the event accumulator"
-    return {k: pd.DataFrame(ea.Scalars(k)) for k in scalars}
-
-a = ["eval/test_episode_return"]
-data = parse_tensorboard("runs/gym_STAR/Fix-v1__ppo_normalizeLayer__2200__1682419347", a)
-data = data[a[0]].to_numpy()
-# data = data[:, 1:]
-x = data[:, 1]
-y = data[:, 2]
-
-print("-")
-
-plt.style.use('_mpl-gallery')
-
-# plot
-fig, ax = plt.subplots()
-
-ax.step(x, y, linewidth=0.5)
-
-# ax.set(xlim=(0, 8), xticks=np.arange(1, 8),
-#        ylim=(0, 8), yticks=np.arange(1, 8))
-
-plt.show()
-
diff --git a/draw_perf.py b/draw_perf.py
new file mode 100644
index 0000000..5e4fb5e
--- /dev/null
+++ b/draw_perf.py
@@ -0,0 +1,81 @@
+import numpy as np
+from tensorboard.backend.event_processing import event_accumulator
+import pandas as pd
+import matplotlib.pyplot as plt
+
+
+def smooth(data, window):
+    length = len(data)
+    result = np.ndarray
+    for _ in range(window-1):
+        data = np.append(data[0], data)
+    for i in range(length):
+        result = np.append(result, np.average(data[i:i+window]))
+    return result[1:]
+
+
+
+def parse_tensorboard(path, scalars):
+    """returns a dictionary of pandas dataframes for each requested scalar"""
+    ea = event_accumulator.EventAccumulator(
+        path,
+        size_guidance={event_accumulator.SCALARS: 0},
+    )
+    _absorb_print = ea.Reload()
+    # make sure the scalars are in the event accumulator tags
+    assert all(
+        s in ea.Tags()["scalars"] for s in scalars
+    ), "some scalars were not found in the event accumulator"
+    return {k: pd.DataFrame(ea.Scalars(k)) for k in scalars}
+
+
+def read_data(path, scalars, window):
+    data = parse_tensorboard(path, scalars)
+    data = data[scalars[0]].to_numpy()
+    # data = data[:, 1:]
+    x = data[:, 1]
+    y = data[:, 2]
+    y = smooth(y, window)
+    return x, y
+
+# a = ["eval/test_episode_return"]
+# data = parse_tensorboard("eva/runs/gym_STAR/My_Env-v1__ppo_normalizeLayer__2200__1682584545", a)
+# data = data[a[0]].to_numpy()
+# # data = data[:, 1:]
+# x = data[:, 1]
+# y = data[:, 2]
+# y = smooth(y, 100)
+
+# x1, y1 = read_data("eva/runs/gym_STAR/My_Env-v1__ppo_normalizeLayer__2200__1682584545", ["eval/test_episode_return"], 100)
+# x2, y2 = read_data("eva/runs/gym_STAR/Fix_Pos-v1__ppo_normalizeLayer__2200__1682772182", ["eval/test_episode_return"], 100)
+# x3, y3 = read_data("eva/runs/gym_STAR/Fix-v1__ppo_normalizeLayer__2200__1682866328", ["eval/test_episode_return"], 100)
+
+x1, y1 = read_data("runs/gym_STAR/My_Env-v1__ppo_normalizeLayer__2200__1682157676", ["eval/test_episode_return"], 100)
+x2, y2 = read_data("runs/gym_STAR/Fix_Pos-v1__ppo_normalizeLayer__2200__1682318791", ["eval/test_episode_return"], 100)
+x3, y3 = read_data("runs/gym_STAR/Fix-v1__ppo_normalizeLayer__2200__1682419347", ["eval/test_episode_return"], 100)
+x4, y4 = read_data("runs/gym_STAR/RIS_Env-v1__ppo_normalizeLayer__2200__1682253681", ["eval/test_episode_return"], 100)
+
+
+print("-")
+
+plt.style.use('_mpl-gallery')
+
+plt.figure()
+plt.xlim((0, 25000000))
+plt.ylim((50, 250))
+x_ticks = np.linspace(0, 25000000, 11)
+y_ticks = np.linspace(50, 250, 5)
+plt.xticks(x_ticks, np.array(x_ticks/50, dtype=int))
+plt.yticks(y_ticks)
+plt.xlabel("episodes")
+plt.ylabel("reward")
+
+plt.step(x1, y1, color="blue", linewidth=0.5, label="STAR-RIS deployment")
+plt.step(x2, y2, color="green", linewidth=0.5, label="STAR-RIS fix position")
+plt.step(x3, y3, color="red", linewidth=0.5, label="STAR-RIS fix position and orientation")
+plt.step(x4, y4, color="yellow", linewidth=0.5, label="no STAR-RIS")
+plt.legend(loc="best")
+plt.show()
+# plt.imsave("eva/figures/data")
+plt.savefig("eva/figures/data")
+
diff --git a/gym-STAR/gym_STAR/env/Fix.py b/gym-STAR/gym_STAR/env/Fix.py
index ee150ad..168c012 100644
--- a/gym-STAR/gym_STAR/env/Fix.py
+++ b/gym-STAR/gym_STAR/env/Fix.py
@@ -78,9 +78,9 @@ class Fix(gym.Env):
         self.STAR_position = [0, 0, 10]
         self.link_position = [0, 0, 0]
         self.type = np.zeros(shape=(self.K, 1))
-        self.P_K_list = np.random.normal(scale=100, size=(3, self.K))
-        self.P_K_list[:, :3] += 200
-        self.P_K_list[:, 3:] -= 200
+        self.P_K_list = np.random.uniform(low=-500, high=500, size=(3, self.K))
+        # self.P_K_list[:, :3] += 200
+        # self.P_K_list[:, 3:] -= 200
         self.P_K_list[2, :] = 0
         self.t = 0
 
@@ -268,9 +268,8 @@ class Fix(gym.Env):
     #TODO reset the environmrnt, user position, time, observation state, STAR position???
     def reset(self, seed=None, options=None):
         super().reset(seed=seed)
-        self.P_K_list = np.random.normal(scale=100, size=(3, self.K))
-        self.P_K_list[:, :3] += 200
-        self.P_K_list[:, 3:] -= 200
+        self.P_K_list = np.random.uniform(low=-500, high=500, size=(3, self.K))
+        # self.P_K_list[:, :] -= 500
         self.P_K_list[2, :] = 0
 
         # self.FD_B_K = np.random.normal(scale=1, size=(self.M, self.K, self.T)) + np.random.normal(scale=1, size=(self.M, self.K, self.T)) * 1j
diff --git a/gym-STAR/gym_STAR/env/Fix_Pos.py b/gym-STAR/gym_STAR/env/Fix_Pos.py
index df8fdf7..91f42f6 100644
--- a/gym-STAR/gym_STAR/env/Fix_Pos.py
+++ b/gym-STAR/gym_STAR/env/Fix_Pos.py
@@ -78,9 +78,8 @@ class Fix_Pos(gym.Env):
         self.STAR_position = [0, 0, 10]
         self.link_position = [0, 0, 0]
         self.type = np.zeros(shape=(self.K, 1))
-        self.P_K_list = np.random.normal(scale=100, size=(3, self.K))
-        self.P_K_list[:, :3] += 200
-        self.P_K_list[:, 3:] -= 200
+        self.P_K_list = np.random.uniform(low=-500, high=500, size=(3, self.K))
+        # self.P_K_list[:, :] -= 500
         self.P_K_list[2, :] = 0
         self.t = 0
 
@@ -266,15 +265,14 @@ class Fix_Pos(gym.Env):
         if self.render_mode == "human":
             self.render_frame()
 
-        return np.array([next_state]).astype(np.float32), self.sum_rate, False, done, {}
+        return np.array([next_state]).astype(np.float32), self.sum_rate, False, done, {"rate": self.data_rate_list, "type": self.type}
 
 
     #TODO reset the environmrnt, user position, time, observation state, STAR position???
     def reset(self, seed=None, options=None):
         super().reset(seed=seed)
-        self.P_K_list = np.random.normal(scale=100, size=(3, self.K))
-        self.P_K_list[:, :3] += 200
-        self.P_K_list[:, 3:] -= 200
+        self.P_K_list = np.random.uniform(low=-500, high=500, size=(3, self.K))
+        # self.P_K_list[:, :] -= 500
         self.P_K_list[2, :] = 0
 
         # self.FD_B_K = np.random.normal(scale=1, size=(self.M, self.K, self.T)) + np.random.normal(scale=1, size=(self.M, self.K, self.T)) * 1j
diff --git a/gym-STAR/gym_STAR/env/My_Env_v1.py b/gym-STAR/gym_STAR/env/My_Env_v1.py
index c3cb5db..03784b4 100644
--- a/gym-STAR/gym_STAR/env/My_Env_v1.py
+++ b/gym-STAR/gym_STAR/env/My_Env_v1.py
@@ -37,7 +37,7 @@ class My_Env(gym.Env):
         self.K = 6    #total users
 
         self.M = 4                  #antenna number
-        self.N = 25                 #STAR-RIS element number
+        self.N = 15                 #STAR-RIS element number
         self.N_h = 5                #horizontal element number
         self.N_v = self.N/self.N_h  #vertical element number
 
@@ -78,9 +78,9 @@ class My_Env(gym.Env):
         self.STAR_position = [0, 0, 10]
         self.link_position = [0, 0, 0]
         self.type = np.zeros(shape=(self.K, 1))
-        self.P_K_list = np.random.uniform(low=-500, high=500, size=(3, self.K))
-        # self.P_K_list[:, :3] += 200
-        # self.P_K_list[:, 3:] -= 200
+        self.P_K_list = np.random.normal(scale=100, size=(3, self.K))
+        self.P_K_list[:, :3] += 200
+        self.P_K_list[:, 3:] -= 200
         self.P_K_list[2, :] = 0
         self.t = 0
 
@@ -268,14 +268,15 @@ class My_Env(gym.Env):
         if self.render_mode == "human":
             self.render_frame()
 
-        return np.array([next_state]).astype(np.float32), self.sum_rate, False, done, {}
+        return np.array([next_state]).astype(np.float32), self.sum_rate, False, done, {"rate": self.data_rate_list, "type": self.type}
 
 
     #TODO reset the environmrnt, user position, time, observation state, STAR position???
     def reset(self, seed=None, options=None):
         super().reset(seed=seed)
-        self.P_K_list = np.random.uniform(low=-500, high=500, size=(3, self.K))
-        # self.P_K_list[:, :] -= 500
+        self.P_K_list = np.random.normal(scale=100, size=(3, self.K))
+        self.P_K_list[:, :3] += 200
+        self.P_K_list[:, 3:] -= 200
         self.P_K_list[2, :] = 0
 
         # self.FD_B_K = np.random.normal(scale=1, size=(self.M, self.K, self.T)) + np.random.normal(scale=1, size=(self.M, self.K, self.T)) * 1j
diff --git a/gym-STAR/gym_STAR/env/RIS_Env.py b/gym-STAR/gym_STAR/env/RIS_Env.py
index e193867..1515fdd 100644
--- a/gym-STAR/gym_STAR/env/RIS_Env.py
+++ b/gym-STAR/gym_STAR/env/RIS_Env.py
@@ -78,9 +78,9 @@ class RIS_Env(gym.Env):
         self.STAR_position = [0, 0, 10]
         self.link_position = [0, 0, 0]
         self.type = np.zeros(shape=(self.K, 1))
-        self.P_K_list = np.random.normal(scale=100, size=(3, self.K))
-        self.P_K_list[:, :3] += 200
-        self.P_K_list[:, 3:] -= 200
+        self.P_K_list = np.random.uniform(low=-500, high=500, size=(3, self.K))
+        # self.P_K_list[:, :3] += 200
+        # self.P_K_list[:, 3:] -= 200
         self.P_K_list[2, :] = 0
         self.t = 0
 
@@ -268,9 +268,8 @@ class RIS_Env(gym.Env):
     #TODO reset the environmrnt, user position, time, observation state, STAR position???
     def reset(self, seed=None, options=None):
         super().reset(seed=seed)
-        self.P_K_list = np.random.normal(scale=100, size=(3, self.K))
-        self.P_K_list[:, :3] += 200
-        self.P_K_list[:, 3:] -= 200
+        self.P_K_list = np.random.uniform(low=-500, high=500, size=(3, self.K))
+        # self.P_K_list[:, :] -= 500
         self.P_K_list[2, :] = 0
 
         # self.FD_B_K = np.random.normal(scale=1, size=(self.M, self.K, self.T)) + np.random.normal(scale=1, size=(self.M, self.K, self.T)) * 1j
diff --git a/ppo_normalizeLayer.py b/ppo_normalizeLayer.py
index 7a41adc..b3d68d7 100644
--- a/ppo_normalizeLayer.py
+++ b/ppo_normalizeLayer.py
@@ -38,7 +38,7 @@ def parse_args():
         help="whether to capture videos of the agent performances (check out `videos` folder)")
 
     # Algorithm specific arguments
-    parser.add_argument("--env-id", type=str, default="gym_STAR/Fix-v1",
+    parser.add_argument("--env-id", type=str, default="gym_STAR/My_Env-v1",
         help="the id of the environment")
     parser.add_argument("--total-timesteps", type=int, default=25000000,
         help="total timesteps of the experiments")
@@ -87,7 +87,7 @@ def make_env(env_id, idx, capture_video, run_name, gamma):
             env = gym.make(env_id, render_mode="rgb_array")
         else:
             env = gym.make(env_id)
-        env = gym.wrappers.FlattenObservation(env)  # deal with dm_control's Dict observation space
+        env = gym.wrappers.FlattenObservation(env)  # deal with dm`_control's Dict observation space
         env = gym.wrappers.RecordEpisodeStatistics(env)
         if capture_video:
             if idx == 0:
@@ -149,7 +149,7 @@ def evaluata_policy_test(env, agent, normalize, gamma_, seed):
             s_, r, terminated, truncated, _ = env.step(torch.Tensor(action))
             s = s_
             reward += r * gamma
-            # gamma *= gamma_
+            gamma *= gamma_
             done = np.logical_or(terminated, truncated)
     return reward / n, steps / n
 
diff --git a/test.py b/test.py
index a85dfe3..7ab168d 100644
--- a/test.py
+++ b/test.py
@@ -43,6 +43,8 @@ steps = 0
 env.obs_rms.mean = mean
 env.obs_rms.var = var
 reward = 0
+infos = []
+count = 0
 for _ in range(n):
     done = False
     gamma = 1
@@ -51,7 +53,9 @@ for _ in range(n):
     while not done:
         steps += 1
         action, logprob, _ = actor.get_action(torch.unsqueeze(torch.Tensor(s), 0))
-        s_, r, terminated, truncated, _ = env.step(torch.Tensor(action))
+        s_, r, terminated, truncated, info = env.step(torch.Tensor(action))
+        infos[count] = info
+        count += 1
         # s_ = (s_ - mean) / np.sqrt(1e-8 + var)
         print(r)
         s = s_
@@ -61,3 +65,4 @@ for _ in range(n):
     print(reward)
 
 env.close()
+np.save("infos", infos)
diff --git a/test_normalizeLayer.py b/test_normalizeLayer.py
index 4c3d2e5..3b62d1b 100644
--- a/test_normalizeLayer.py
+++ b/test_normalizeLayer.py
@@ -21,6 +21,8 @@ device = torch.device("cpu")
 n = 3
 steps = 0
 reward = 0
+infos = []
+count = 0
 for _ in range(n):
     done = False
     gamma = 1
@@ -29,7 +31,11 @@ for _ in range(n):
     while not done:
         steps += 1
         action, logprob, _ = actor.get_action(torch.unsqueeze(torch.Tensor(s), 0))
-        s_, r, terminated, truncated, _ = env.step(torch.Tensor(action))
+        s_, r, terminated, truncated, info = env.step(torch.Tensor(action))
+        # infos[count] = info
+        # count += 1
+        infos.append(np.array(info["rate"]))
+        count += 1
         # s_ = (s_ - mean) / np.sqrt(1e-8 + var)
         print(r)
         s = s_
@@ -39,3 +45,4 @@ for _ in range(n):
     print(reward)
 
 env.close()
+np.save("infos", infos)
diff --git a/wandb/debug-cli.JinLab.log b/wandb/debug-cli.JinLab.log
index 2d9c106..7e9fdea 100644
--- a/wandb/debug-cli.JinLab.log
+++ b/wandb/debug-cli.JinLab.log
@@ -554,3 +554,24 @@ requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='api.wandb.ai', port=4
 2023-04-25 18:44:09 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
 2023-04-25 18:44:09 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
 2023-04-25 18:44:09 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-04-27 16:37:07 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-04-27 16:37:07 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-04-27 16:37:07 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-04-28 22:05:09 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-04-28 22:05:09 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-04-28 22:05:09 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-04-29 20:44:29 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-04-29 20:44:29 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-04-29 20:44:29 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-04-30 22:53:22 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-04-30 22:53:22 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-04-30 22:53:22 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-05-02 16:16:08 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-05-02 16:16:08 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-05-02 16:16:08 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-05-03 21:46:01 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-05-03 21:46:01 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-05-03 21:46:01 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-05-05 16:26:42 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-05-05 16:26:42 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
+2023-05-05 16:26:42 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)'))': /api/5288891/envelope/
